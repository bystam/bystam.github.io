---
layout: post
title: "Are we in a software bubble?"
date: 2030-11-30 11:00:44 +0200
categories: takes
---

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Every time I see an AI button in a UI somewhere I cringe and ignore it. Simultaneously I’m going nuts with my agents. Why is consumer AI so shit? <a href="https://t.co/6tVxCFCabR">https://t.co/6tVxCFCabR</a></p>&mdash; Armin Ronacher ⇌ (@mitsuhiko) <a href="https://twitter.com/mitsuhiko/status/2010406878870643086?ref_src=twsrc%5Etfw">January 11, 2026</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

There is something that has been bugging me in the back of my mind for the past few months. Some kind of feeling that what I am hearing and reading is not what is truly happening. Yes, this is yet another blog post about AI. Hopefully one that contains something novel.

As I said - I feel like there is something brewing - something people are not talking about. This is not about people being fraudulent, or gaslighting us, although I suspect there is some amount of that going on too. A lot of people talk about the "AI bubble" right now. Anecdotally, it feels like a majority of people in tech agree/suspect that there is one. Even a substantial amount of people who love LLMs and have close to completely stopped writing code by hand will admit that there likely is some level of bubble in the industry.

What I am wondering, however, is if that is missing the mark. What if we're not in an AI bubble - **but a software one**?

## The great promises of AI

LLMs and the tools built on top of them are an obvious breakthrough in digital technology. Their ability to "understand" text is unparalleled, and using dialogue to research and understand topics are striking improvements when compared to reading the internet through Google. Especially since the years leading up to the release of ChatGPT saw an absoultely horrendous enshittification of what used to be a remarkable search engine.

The market hype responded accordingly. Nvidia, a company that literally creates a single kind of hardware, rose to become the most valuable company in the world - and AI-native companies like Lovable are valued at [ridiculous sums](https://lovable.dev/blog/series-b) after only a single year of existence.

The writing on the wall is clear: at some point in the near future, LLMs/AI will create more value for society than we can possibly imagine. Or, that's what the investments assume anyway.

### The AI sceptics

The sceptics will tell you that all of this is a bubble:

- LLMs are not as good as they appear. They just feel like it because they are generating text, which creates an "illusion of intelligence".
- LLMs, while they can surely generate code, cannot generate good enough code at a large scale to be truly valuable
- LLMs is a crutch that lets people avoid learning

You have heard these takes before. The people bearish on AI think that the LLMs will fail to live up to the hype, and that the markets will crash. This is nothing new.

But that is not what is bugging me. What I am starting to wonder is this: What if there is nothing wrong with the LLMs capabilities. **What if we are simply unable to build anything useful with them?**

Let me explain what I mean.

### The trajectory

Think of the significant software you use today. Then think about all the software you used 10 years ago. How much has changed? For me, not a lot. For work, I use Slack, Google Drive/Docs, Jetbrains IDEs for programming and Google Chrome for web browsing. I used Spotify for listening to music, Netflix for streaming movies and TV shows. On my smartphone, I use Facebook messenger, WhatsApp, Twitter and Youtube.

In 2016, literally all of that was the same. The only new significant piece of software during that decade are the LLM tools.

Now compare that to the 10 years prior, between 2006 and 2016. In 2006, most of the apps listed either did not exist or were in their infancy. Smartphones had not yet hit the mainstream, there were no app stores. Google has not yet released a web browser.

Tiktok is an obvious omission from my list (since I don't use it) that actually was released in the past 10 years. But with the evidence that is connecting social media like Tiktok with severe mental health problems in kids, and with the US congress even going so far as considering it a serious threat to national security, can we really call it useful?

If we look at the last 20 years, there seems to be an extremely visible plateau in the production of useful software. It appears that all our ideas for creating a better world using computers have stagnated.

- TODO: insert examples of Windows, Liquid glass etc

Now

### AI for writing code faster

Last year was a bit of a watershed moment for LLM-assisted programming. With the release of Opus 4.5 and ChatGPT 5.2, a serious amount of independently minded software influencers changed their mind from "AI cannot write good production code" to "actually AI writes most of my code now".

To me it looks like the tide is turning. Maybe this is not just an astroturfed fad that will pass in a year or two. Maybe most people will truly write code using "Agents" (or whatever comes next) in the near future. Heck, what if the models get good enough to simply help all of us write just as good code we would write by hand - but at a significantly higher pace. If that happens, then the AI hypesters will have won, right?

### AI for building new user experiences

## Learnings from the internet

###
